{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import json\n",
    "import PIL\n",
    "from PIL import ImageDraw, ImageFont,Image, ImageOps, ImageEnhance\n",
    "from matplotlib import patches, patheffects\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from functools import partial\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms,models\n",
    "from torchvision.utils import make_grid\n",
    "import math\n",
    "import random\n",
    "import numbers\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import glob\n",
    "from skimage import io\n",
    "from torch.autograd import Variable as V\n",
    "from scipy import ndimage\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import skimage\n",
    "torch.backends.cudnn.benchmark=True\n",
    "torch.cuda.set_device(0)\n",
    "import scipy\n",
    "def sum_geom(a,r,n): return a*n if r==1 else math.ceil(a*(1-r**n)/(1-r))\n",
    "def is_listy(x): return isinstance(x, (list,tuple))\n",
    "def is_iter(x): return isinstance(x, collections.Iterable)\n",
    "def map_over(x, f): return [f(o) for o in x] if is_listy(x) else f(x)\n",
    "def map_none(x, f): return None if x is None else f(x)\n",
    "def delistify(x): return x[0] if is_listy(x) else x\n",
    "def listify(x, y):\n",
    "    if not is_iter(x): x=[x]\n",
    "    n = y if type(y)==int else len(y)\n",
    "    if len(x)==1: x = x * n\n",
    "    return x\n",
    "\n",
    "def datafy(x):\n",
    "    if is_listy(x): return [o.data for o in x]\n",
    "    else:           return x.data\n",
    "\n",
    "conv_dict = {np.dtype('int8'): torch.LongTensor, np.dtype('int16'): torch.LongTensor,\n",
    "    np.dtype('int32'): torch.LongTensor, np.dtype('int64'): torch.LongTensor,\n",
    "    np.dtype('float32'): torch.FloatTensor, np.dtype('float64'): torch.FloatTensor}\n",
    "\n",
    "def A(*a):\n",
    "    \"\"\"convert iterable object into numpy array\"\"\"\n",
    "    return np.array(a[0]) if len(a)==1 else [np.array(o) for o in a]\n",
    "\n",
    "def T(a, half=False, cuda=True):\n",
    "    \"\"\"\n",
    "    Convert numpy array into a pytorch tensor. \n",
    "    if Cuda is available and USE_GPU=True, store resulting tensor in GPU.\n",
    "    \"\"\"\n",
    "    if not torch.is_tensor(a):\n",
    "        a = np.array(np.ascontiguousarray(a))\n",
    "        if a.dtype in (np.int8, np.int16, np.int32, np.int64):\n",
    "            a = torch.LongTensor(a.astype(np.int64))\n",
    "        elif a.dtype in (np.float32, np.float64):\n",
    "            a = to_half(a) if half else torch.FloatTensor(a)\n",
    "        else: raise NotImplementedError(a.dtype)\n",
    "    if cuda: a = to_gpu(a)\n",
    "    return a\n",
    "\n",
    "def to_half(tensor):\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.cuda.HalfTensor(tensor)\n",
    "    else:\n",
    "        return torch.FloatTensor(tensor)\n",
    "\n",
    "def create_variable(x, volatile, requires_grad=False):\n",
    "    if type (x) != Variable:\n",
    "        x = Variable(T(x), requires_grad=requires_grad, volatile=volatile)\n",
    "    return x\n",
    "\n",
    "def V_(x, requires_grad=False, volatile=False):\n",
    "    '''equivalent to create_variable, which creates a pytorch tensor'''\n",
    "    return create_variable(x, volatile=volatile, requires_grad=requires_grad)\n",
    "def V(x, requires_grad=False, volatile=False):\n",
    "    '''creates a single or a list of pytorch tensors, depending on input x. '''\n",
    "    return map_over(x, lambda o: V_(o, requires_grad, volatile))\n",
    "\n",
    "def VV_(x): \n",
    "    '''creates a volatile tensor, which does not require gradients. '''\n",
    "    return create_variable(x, True)\n",
    "\n",
    "def VV(x):\n",
    "    '''creates a single or a list of pytorch tensors, depending on input x. '''\n",
    "    return map_over(x, VV_)\n",
    "\n",
    "def to_np(v):\n",
    "    '''returns an np.array object given an input of np.array, list, tuple, torch variable or tensor.'''\n",
    "    if isinstance(v, float): return np.array(v)\n",
    "    if isinstance(v, (np.ndarray, np.generic)): return v\n",
    "    if isinstance(v, (list,tuple)): return [to_np(o) for o in v]\n",
    "    if isinstance(v, Variable): v=v.data\n",
    "    if torch.cuda.is_available():\n",
    "        if is_half_tensor(v): v=v.float()\n",
    "    if isinstance(v, torch.FloatTensor): v=v.float()\n",
    "    return v.cpu().numpy()\n",
    "\n",
    "def is_half_tensor(v):\n",
    "    return isinstance(v, torch.cuda.HalfTensor)\n",
    "\n",
    "\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "def to_gpu(x, *args, **kwargs):\n",
    "    '''puts pytorch variable to gpu, if cuda is available and USE_GPU is set to true. '''\n",
    "    return x.cuda(*args, **kwargs) if USE_GPU else x\n",
    "\n",
    "def noop(*args, **kwargs): return\n",
    "\n",
    "def trainable_params_(m):\n",
    "    '''Returns a list of trainable parameters in the model m. (i.e., those that require gradients.)'''\n",
    "    return [p for p in m.parameters() if p.requires_grad]\n",
    "\n",
    "def chain_params(p):\n",
    "    if is_listy(p):\n",
    "        return list(chain(*[trainable_params_(o) for o in p]))\n",
    "    return trainable_params_(p)\n",
    "\n",
    "def set_trainable_attr(m,b):\n",
    "    m.trainable=b\n",
    "    for p in m.parameters(): p.requires_grad=b\n",
    "\n",
    "def apply_leaf(m, f):\n",
    "    c = children(m)\n",
    "    if isinstance(m, nn.Module): f(m)\n",
    "    if len(c)>0:\n",
    "        for l in c: apply_leaf(l,f)\n",
    "def children(m): return m if isinstance(m, (list, tuple)) else list(m.children())\n",
    "def set_trainable(l, b):\n",
    "    apply_leaf(l, lambda m: set_trainable_attr(m,b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filenametoid = json.load((PATH/'filename_id.json').open())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetIndex(n, cv_idx=0, val_pct=0.2, seed=42):\n",
    "    n=n-1\n",
    "    np.random.seed(seed)\n",
    "    n_val = int(val_pct*n)\n",
    "    idx_start = cv_idx*n_val\n",
    "    idxs = np.random.permutation(n)\n",
    "    val=idxs[idx_start:idx_start+n_val]\n",
    "    val=set(val)\n",
    "    train=[]\n",
    "    for i in tqdm(range(n+1)):\n",
    "        if(i not in val):\n",
    "            train.append(i)\n",
    "    return train,list(val)\n",
    "def GETCSV(df):\n",
    "    train_csv,val_csv=GetIndex(len(df))\n",
    "    return df.iloc[train_csv],df.iloc[val_csv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file= pd.read_csv(PATH/'labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv,val_csv=GETCSV(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(Dataset):\n",
    "   \n",
    "    def __init__(self, csv_file, root_dir, n_class, transform=None):\n",
    "        \n",
    "        self.csv_file = csv_file\n",
    "        array=[]\n",
    "        for i,fn in zip(csv_file['category'],csv_file['image_name']):\n",
    "            array.append((fn,i))\n",
    "        self.file_label=array\n",
    "        self.root_dir = root_dir\n",
    "        self.classes=n_class\n",
    "        self.transform = transform\n",
    "        self.grey=transforms.Grayscale(num_output_channels=3)\n",
    "    def __len__(self):\n",
    "        return len(self.csv_file)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.file_label[idx][0])\n",
    "        images = Image.open(img_name).convert('RGB')\n",
    "        labels = self.file_label[idx][1]\n",
    "        images = self.transform(images)        \n",
    "        return images,torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=train_data[3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=to_np(a.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=DataSet(train_csv,PATH/'images/',37,transform=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data=DataSet(val_csv,PATH/'images/',37,transform=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(train_data,batch_size=20,shuffle=True ,num_workers=0 , pin_memory=True)\n",
    "valid_loader=DataLoader(valid_data,batch_size=20,shuffle=True ,num_workers=0 , pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[103][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {'train': train_loader,'valid':valid_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes={'train':len(train_data),'valid':len(valid_data)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveConcatPool2d(nn.Module):\n",
    "    def __init__(self, sz=None):\n",
    "        super().__init__()\n",
    "        sz = sz or (1,1)\n",
    "        self.ap = nn.AdaptiveAvgPool2d(sz)\n",
    "        self.mp = nn.AdaptiveMaxPool2d(sz)\n",
    "    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)\n",
    "    \n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self, keep_batch_dim=True):\n",
    "        super().__init__()\n",
    "        self.keep_batch_dim = keep_batch_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.keep_batch_dim:\n",
    "            return x.view(x.size(0), -1)\n",
    "        return x.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = models.resnet34(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "layers=[Flatten(),nn.BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "       nn.Dropout(p=0.25), nn.Linear(in_features=1024, out_features=512, bias=True),\n",
    "       nn.ReLU(),nn.BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "       nn.Dropout(p=0.5),nn.Linear(in_features=512, out_features=37, bias=True),nn.LogSoftmax()]\n",
    "model_conv.avgpool=AdaptiveConcatPool2d(1)\n",
    "model_conv.fc=nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_period=len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_embedding(labels, num_classes):\n",
    "    labels=labels.type(torch.long)\n",
    "    return torch.eye(num_classes)[labels.data.cpu()]\n",
    "\n",
    "class BCE(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "    \n",
    "    def forward(self, preds, targets):\n",
    "        t = one_hot_embedding(targets, self.num_classes+1)\n",
    "        t = V(t[:,:-1].contiguous()) \n",
    "        return F.binary_cross_entropy_with_logits(preds, t,size_average=False) / self.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = BCE(37).cuda()\n",
    "model_conv = model_conv.cuda()\n",
    "optimizer = optim.SGD(model_conv.fc.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgdr(period, batch_idx):\n",
    "    batch_idx = float(batch_idx)\n",
    "    restart_period = period\n",
    "    while batch_idx/restart_period > 1.:\n",
    "        batch_idx = batch_idx - restart_period\n",
    "        restart_period = restart_period * 2.\n",
    "\n",
    "    radians = math.pi*(batch_idx/restart_period)\n",
    "    return 0.5*(1.0 + math.cos(radians))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_optimizer_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_trace=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    model_conv.train()\n",
    "    global optimizer\n",
    "    start_batch_idx = len(train_loader)*epoch\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        global_step = batch_idx+start_batch_idx\n",
    "        batch_lr = lr*sgdr(lr_period, global_step)\n",
    "        lr_trace.append(batch_lr)\n",
    "        optimizer = set_optimizer_lr(optimizer, batch_lr)\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = V(inputs), V(targets)\n",
    "        outputs = model_conv(inputs)\n",
    "#         print(outputs.shape)\n",
    "#         print(targets.shape)\n",
    "        loss = criterion(outputs.cuda(), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.data.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "        print(batch_idx, len(train_loader), 'Loss: %.3f | Acc: %.3f%% (%d/%d) | LR: %.3f'\n",
    "            % (train_loss/(batch_idx+1), 100.*correct/total, correct, total, batch_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_sgdr(num_cycle=3):\n",
    "    epoch=2**num_cycle-1\n",
    "    lr_trace=[]\n",
    "    for e in range(epoch):\n",
    "        train(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_sgdr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_conv.state_dict(), PATH/'modelsgd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv.load_state_dict(torch.load(PATH/'modelsgd.h5'), strict=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
